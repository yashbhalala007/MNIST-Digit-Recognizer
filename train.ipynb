{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvg0p6udct16"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.utils.data as T\r\n",
        "import os\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "def create_loader(data):\r\n",
        "  df_labels = data['label'] \r\n",
        "  df_img = data.drop(['label'], 1)\r\n",
        "\r\n",
        "  train_img_tensor = (torch.from_numpy(df_img.values).float() / 255).to(device)\r\n",
        "  train_label_tensor = (torch.from_numpy(df_labels.values)).to(device)\r\n",
        "\r\n",
        "  fc_dataset = T.TensorDataset(train_img_tensor, train_label_tensor)\r\n",
        "  cnn_dataset = T.TensorDataset(train_img_tensor.view(-1, 1, 28, 28), train_label_tensor)\r\n",
        "  \r\n",
        "  fc_train_ds, fc_valid_ds = T.random_split(fc_dataset, [29400, 12600])\r\n",
        "  cnn_train_ds, cnn_valid_ds = T.random_split(cnn_dataset, [29400, 12600])\r\n",
        "  \r\n",
        "  fc_train_dl = T.DataLoader(fc_train_ds, batch_size = 16)\r\n",
        "  fc_valid_dl = T.DataLoader(fc_valid_ds, batch_size = 16)\r\n",
        "  \r\n",
        "  cnn_train_dl = T.DataLoader(cnn_train_ds, batch_size = 16)\r\n",
        "  cnn_valid_dl = T.DataLoader(cnn_valid_ds, batch_size = 16)\r\n",
        "  \r\n",
        "  return (fc_train_dl, fc_valid_dl, cnn_train_dl, cnn_valid_dl)\r\n",
        "\r\n",
        "def train_model(train_dl, valid_dl, net, criterion, optimizer):\r\n",
        "  for i in range(5):\r\n",
        "    print(f\"\\n================epoch {i+1}================\\n\")\r\n",
        "    epoch(train_dl, valid_dl, net, criterion, optimizer)\r\n",
        "\r\n",
        "def epoch(train_dl, valid_dl, net, criterion, optimizer):\r\n",
        "  train_loss, train_acc = train_epoch(train_dl, net, criterion, optimizer)\r\n",
        "  valid_loss, valid_acc = valid_epoch(valid_dl, net, criterion)\r\n",
        "  print(\"==========Training==========\")\r\n",
        "  print(f\"Loss: {train_loss}, Accuracy: {train_acc}\")\r\n",
        "  print(\"=========Validation=========\")\r\n",
        "  print(f\"Loss: {valid_loss}, Accuracy: {valid_acc}\")\r\n",
        "\r\n",
        "def train_epoch(dl, net, criterion, optimizer):\r\n",
        "  net.train()\r\n",
        "  correct, total = 0, 0\r\n",
        "  total_loss = 0\r\n",
        "  for data in dl:\r\n",
        "    input, label = data\r\n",
        "    optimizer.zero_grad()\r\n",
        "    output = net(input)\r\n",
        "    loss = criterion(output, label)\r\n",
        "    total_loss += loss.cpu().item()\r\n",
        "    correct += cal_acc(output, label)\r\n",
        "    total += len(label)\r\n",
        "    loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "  return (total_loss/total, correct/total)\r\n",
        "\r\n",
        "def valid_epoch(dl, net, criterion):\r\n",
        "  net.eval()\r\n",
        "  correct, total = 0, 0\r\n",
        "  total_loss = 0\r\n",
        "  with torch.no_grad():\r\n",
        "    for data in dl:\r\n",
        "      input, label = data\r\n",
        "      output = net(input)\r\n",
        "      loss = criterion(output, label)\r\n",
        "      total_loss += loss.cpu().item()\r\n",
        "      correct += cal_acc(output, label)\r\n",
        "      total += len(label)\r\n",
        "  return (total_loss/total, correct/total) \r\n",
        "\r\n",
        "def cal_acc(pred, label):\r\n",
        "  correct = 0\r\n",
        "  for indx, i in enumerate(pred):\r\n",
        "    if torch.argmax(i) == label[indx]:\r\n",
        "      correct += 1\r\n",
        "  return correct\r\n",
        "\r\n",
        "class NNet(nn.Module):\r\n",
        "\r\n",
        "  def __init__(self):\r\n",
        "    super().__init__()\r\n",
        "    self.fc = nn.Sequential(\r\n",
        "      nn.Linear(784, 500),\r\n",
        "      nn.BatchNorm1d(500),\r\n",
        "      nn.ReLU(),\r\n",
        "      nn.Linear(500, 500),\r\n",
        "      nn.BatchNorm1d(500),\r\n",
        "      nn.ReLU(),\r\n",
        "      nn.Linear(500, 10)\r\n",
        "    )\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    x = self.fc(x)\r\n",
        "    return x\r\n",
        "\r\n",
        "class CNNet(nn.Module):\r\n",
        "\r\n",
        "  def __init__(self):\r\n",
        "    super().__init__()\r\n",
        "    self.conv = nn.Sequential(\r\n",
        "      nn.Conv2d(1, 32, 5), #conv 1\r\n",
        "      nn.BatchNorm2d(32),\r\n",
        "      nn.ReLU(),\r\n",
        "      nn.MaxPool2d(2),\r\n",
        "      nn.Conv2d(32, 64, 3),  #conv 2\r\n",
        "      nn.BatchNorm2d(64),\r\n",
        "      nn.ReLU(),\r\n",
        "      nn.MaxPool2d(2),\r\n",
        "      nn.Conv2d(64, 128, 2), #conv 3\r\n",
        "      nn.BatchNorm2d(128),\r\n",
        "      nn.ReLU(),\r\n",
        "      nn.MaxPool2d(2)\r\n",
        "    )\r\n",
        "\r\n",
        "    self.fc = nn.Sequential(\r\n",
        "      nn.Linear(128*2*2, 500), #fc 1\r\n",
        "      nn.BatchNorm1d(500),\r\n",
        "      nn.ReLU(),\r\n",
        "      nn.Linear(500, 500), #fc 2\r\n",
        "      nn.BatchNorm1d(500),\r\n",
        "      nn.ReLU(),\r\n",
        "      nn.Linear(500, 10) #out\r\n",
        "    )\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    x = self.conv(x)\r\n",
        "    x = x.view(x.size(0), -1)\r\n",
        "    x = self.fc(x)\r\n",
        "    return x\r\n",
        "\r\n",
        "if __name__ == \"__main__\":\r\n",
        "  device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\r\n",
        "\r\n",
        "  os.chdir('drive/MyDrive/Digit Recognizer')\r\n",
        "\r\n",
        "  train = pd.read_csv('train.csv')\r\n",
        "\r\n",
        "  fc_train_dl, fc_valid_dl, cnn_train_dl, cnn_valid_dl = create_loader(train)\r\n",
        "\r\n",
        "  fc_net = NNet().to(device)\r\n",
        "  cnn_net = CNNet().to(device)\r\n",
        "  criterion = nn.CrossEntropyLoss().to(device)\r\n",
        "  fc_optimizer = optim.Adam(fc_net.parameters(), lr = 0.001)\r\n",
        "  cnn_optimizer = optim.Adam(cnn_net.parameters(), lr = 0.001)\r\n",
        "\r\n",
        "  print(\"======================Normal NN======================\")\r\n",
        "  train_model(fc_train_dl, fc_valid_dl, fc_net, criterion, fc_optimizer)\r\n",
        "  torch.save(fc_net, \"Models/fc_net.pth\")\r\n",
        "  print(\"\\n\\n======================CNN======================\")\r\n",
        "  train_model(cnn_train_dl, cnn_valid_dl, cnn_net, criterion, cnn_optimizer)\r\n",
        "  torch.save(cnn_net, \"Models/cnn_net.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}